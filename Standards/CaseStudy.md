# Case Study and Ethnography 
<standard name="Case Study and Ethnography">

"An empirical inquiry that investigates a contemporary phenomenon (the
"case") in depth and within its real-world context, especially when the
boundaries between phenomenon and context \[are unclear\]" (Yin 2017)

## Application 

This standard applies to empirical research that meets the following
conditions.

-   Presents a detailed account of a specific instance of a *phenomenon*
    at a *site*. The phenomenon can be virtually anything of interest
    (e.g. Unix, cohesion metrics, communication issues). The site can be
    a community, an organization, a team, a person, a process, an
    internet platform, etc.

-   Features direct or indirect observation (e.g. interviews, focus
    groups)---see Lethbridge et al.'s (2005) taxonomy.

-   Is not an experience report (cf. Perry et al. 2004) or a series of
    shallow inquiries at many different sites.

A case study can be brief (e.g. a week of observation) or longitudinal
(if observation exceeds the natural rhythm of the site; e.g., observing
a product over many releases). For our purposes, *case study subsumes
ethnography*.

If data collection and analysis are interleaved, consider the **Grounded
Theory Standard**. If the study mentions action research, or intervenes
in the context, consider the **Action Research Standard.** If the study
captures a large quantitative dataset with limited context, consider the
**Exploratory Data Science Standard.**

## Specific Attributes 

### Essential Attributes
<checklist name="Essential">
-   explains why the case study approach is appropriate for the research question
-   justifies the selection of the case or site that was studied
-   describes the context of the case in rich detail
-   defines unit(s) of analysis
-   presents a clear and well-argued "chain of evidence" from observations to findings
-   clearly answers the research question(s)
</checklist>
    
### Desirable Attributes
<checklist name="Desirable">
-   reports the type of case study (see *Types of Case Studies*, below)
-   describes external events and other factors that may have affected the case or site
-   explains how researchers triangulated across data sources, informants or researchers
-   cross-checks interviewee statements (e.g. against direct observation or archival records)
-   uses quotations to *illustrate* findings (note: quotations should not be *the only* representation of a finding; each finding should be described independently of supporting quotations)
</checklist>
    
### Extraordinary Attributes
<checklist name="Extraordinary">
-   multiple, deep, fully-developed cases with cross-case triangulation
-   uses multiple judges and reports inter-rater reliability (cf. Gwet & Gwet 2002)
-   uses direct observation and clearly integrates direct observations into results
-   created a case study protocol beforehand and makes it publicly accessible
</checklist>
    
## General Quality Criteria 

Case studies should be evaluated using qualitative validity criteria
such as credibility, multivocality, reflexivity, rigor and
transferability (see **Glossary**). Quantitative quality criteria such
as replicability, generalizability and objectivity typically do not
apply.

## Types of Case Studies 

There is no standard way of conducting a case study. Case study research
can adopt different philosophies, most notably (post-)positivism (Lee
1989) and interpretivism/constructivism (Walsham 1995), and serve
different purposes, including:

-   a **descriptive case study** describes---in vivid detail--a
    particular instance of a phenomenon

-   an **emancipatory case study** identifies social, cultural, or
    political domination "that may hinder human ability" (Runeson and
    Host 2009), commensurate with a critical epistemological stance

-   an **evaluative case study** evaluates a priori research questions,
    propositions, hypotheses or technological artifacts

-   an **explanatory case study** explains how or why a phenomenon
    occurred, typically using a process or variance theory

-   an **exploratory case study** explores a particular phenomenon to
    identify new questions, propositions or hypotheses

-   an **historical case study** draws on archival data, for instance,
    software repositories

-   a **revelatory case study** examines a hitherto unknown or
    unexplored phenomenon

## Antipatterns 

-   Relying on a single approach to data collection (e.g. interviews)
    without corroboration or triangulation

-   Oversimplifying and over-rationalizing complex phenomena; presenting
    messy complicated things as simple and clean

## Invalid Criticisms 

-   Does not present quantitative data; only collects a single data
    type.

-   Sample of 1; findings not generalizable. The point of a case study
    is to study one thing deeply, not to generalize to a population.
    Case studies should lead to theoretical generalization; that is,
    concepts that are transferable in principle.

-   Lack of internal validity. Internal validity only applies to
    explanatory case studies that seek to establish causality.

-   Lack of reproducibility or a "replication package"; Data are not
    disclosed (qualitative data are often confidential).

-   Insufficient number of length of interviews. There is no magic
    number; what matters is that there is enough data that the findings
    are credible, and the description is deep and rich.

## Suggested Readings 

Line Dube and Guy Pare. Rigor in information systems positivist case
re-search: current practices, trends, and recommendations. 2003. *MIS
quarterly.* JSTOR 27, 4 (Dec. 2003), 597–636. DOI: 10.2307/30036550

Shiva Ebneyamini, and Mohammad Reza Sadeghi Moghadam. 2018. Toward
Developing a Framework for Conducting Case Study Research.
*International Journal of Qualitative Methods.* 17, 1 (Dec. 2018)

Kilem Gwet. 2002. Inter-Rater Reliability: Dependency on Trait
Prevalence and Marginal Homogeneity. Statistical Methods for Inter-Rater
Reliability Assessment Series, 2 (May 2002), 9 pages.

Barbara Kitchenham, Lesley Pickard, and Shari Lawrence Pfleeger. 1995.
Case studies for method and tool evaluation. *IEEE software.* 12, 4
(1995), 52–62.

Timothy C. Lethbridge, Susan Elliott Sim, and Janice Singer. 2005.
Studying software engineers: Data collection techniques for software
field studies. *Empirical software engineering.* 10, 3 (2005), 311–341.

Mathew Miles, A Michael Huberman and Saldana Johnny. 2014. *Qualitative
data analysis: A methods sourcebook*.

Dewayne E. Perry, Susan Elliott Sim, and Steve M. Easterbrook. 2004.
Case Studies for Software Engineers, In *Proceedings 26th International
Conference on Software Engineering.* 28 May 2008, Edinburgh, UK,
736–738.

Per Runeson and Martin Höst. 2009. Guidelines for conducting and
reporting case study research in software engineering. *Empirical
software engineering*. 14, 2, 131 pages.

Per Runeson, Martin Host, Austen Rainer, and Bjorn Regnell. 2012. Case
study research in software engineering: Guidelines and examples. John
Wiley & Sons.

Sarah J. Tracy. 2010. Qualitative Quality: Eight "Big-Tent" Criteria for
Excellent Qualitative Research. *Qualitative Inquiry*. *16*, 10,
837–851. DOI:
[10.1177/1077800410383121](https://doi.org/10.1177/1077800410383121)

Geoff Walsham, 1995. Interpretive case studies in IS research: nature
and method. *European Journal of information systems.* 4,2, 74–81.

Robert K. Yin. 2017. *Case study research and applications: Design and
methods*. Sage publications.

## Exemplars 

Adam Alami, and Andrzej Wąsowski. 2019. Affiliated participation in open
source communities. In *2019 ACM/IEEE International Symposium on
Empirical Software Engineering and Measurement (ESEM)*. 1–11

Michael Felderer and Rudolf Ramler. 2016. Risk orientation in software
testing processes of small and medium enterprises: an exploratory and
comparative study. *Software Quality Journal*. 24, 3 (2016), 519–548.

Audris Mockus, Roy T. Fielding, and James D. Herbsleb. 2002. Two case
studies of open source software development: Apache and Mozilla. *ACM
Transactions on Software Engineering and Methodology (TOSEM).* 11, 3
(2002), 309–346.

Helen Sharp and Hugh Robinson. 2004. An ethnographic study of XP
practice. *Empirical Software Engineering.* 9, 4 (2004), 353–375.

Diomidis Spinellis and Paris C. Avgeriou. Evolution of the Unix System
Architecture: An Exploratory Case Study. *IEEE Transactions on Software
Engineering*. (2019).

Klaas-Jan Stol and Brian Fitzgerald. Two's company, three's a crowd: a
case study of crowdsourcing software development. In *Proceedings of the
36^th^ International Conference on Software Engineering*, 187–198,
2014.
</standard>