# Replication
<standard name="Replication">


*<desc>A study that deliberately repeats a previous study (the "original study") to determine whether its results can be reproduced.</desc>* (Carver et al., 2013)


## Application 

This standard applies to empirical studies that meet the following criteria:

- The replication attempt is deliberate and planned, not accidental overlap with a previous study.
- The original study is clearly identified as a separate previous publication. If the replication is not the only replication of the original study, i.e., it is a part of a *family of replications*, all the other replications are identified and the current replication is clearly defined in the context of the family.
  
## Definitions
  
To _reproduce_ means to repeat the original study's data analysis on the original study's data.
  
To _replicate_ means to repeat a study by collecting new data and repeating the original study's analysis on the new data.


## Specific Attributes
### Essential
<checklist name="Essential">

<intro>

- [ ] discusses the motivation for conducting the replication in appropriate detail (e.g. to validate the results, to broaden the results by changing the participant pool or the artifacts)
- [ ] defines the type of the replication by methodological similarity (exact, methodological, conceptual)<sup>[2](#footnote2)</sup>
- [ ] defines the type of the replication by overlap (partial, complete, extended)<sup>[3](#footnote3)</sup>
- [ ] defines the type of the replication by participants (internal, external, mixed)<sup>[4](#footnote4)</sup>

<method>

- describes the original study in appropriate detail, including:
  - [ ] the research questions of the original study
  - [ ] the design of the original study 
  - [ ] if applicable, the participants of the original study (their number and any relevant characteristics)
  - [ ] the artifacts of the original study
  - [ ] the context variables of the original study that might have affected the design of the study or interpretation of the results
  - [ ] the major findings of the original study
- [ ] EITHER: describes overlap or interactions with the original study author(s)<br/>
        OR: confirms that the original study author(s) were not involved in the replication 
- [ ] describes and justifies any differences from the original study (design, participants, artifacts, procedures, data collection, or analysis)

<results>

- [ ] compares the results of the replication to the results of the original study
- [ ] clearly differentiates between results that are consistent and inconsistent with the original study

<discussion>

<conclusion>
  
<other>

</checklist>

### Desirable
<checklist name="Desirable">

- [ ] reporting of information about (i) the original study, (ii) the replication, (iii) the comparison of results, and (iv) conclusions are clearly separated<sup>[1](#footnote1)</sup>


<method>
	
- [ ] improves on the original study in some way (e.g. design, analysis, statistical power)
- for *families of replications*:
  - [ ] provides a brief summary of the previous studies and replications, including information about how the studies were related, conclusions drawn and current state of knowledge about the topic 
  - [ ] places the results into the context of the entire family of studies 
  - [ ] draws conclusions based on analysis of the results of the entire family of studies 	
  
<results>

- [ ] differentiates between minor and major differences when discussing inconsistent results, elaborates on whether the differences are reasonable and/or expected
	
	
<discussion>

- [ ] draws conclusions across the two (or more) studies; provides insights that would not have been evident from either study individually
- [ ] highlights any conclusions of the original study that were strengthened
- [ ] compares the limitations of the replication to the limitations of the original study
- [ ] proposes hypotheses about new context variables that may have become evident through the analysis of multiple studies

</checklist> 


### Extraordinary
<checklist name="Extraordinary">

<results>

<discussion>

</checklist> 

## Invalid Criticisms
- The replication merely confirms the findings of the original study; no inconsistencies are reported.
- Failing to publish (e.g. in a replication package) materials owned by the original study authors who have not given permission to publish them. 
- Criticizing the research questions including their wording or formulation (since the research questions are set in the original study, the replication must follow them, even in conceptual replications).

## Suggested Readings
- J. C. Carver, “[Towards reporting guidelines for experimental replications: A proposal](http://carver.cs.ua.edu/Papers/Conference/2010/2010_RESER.pdf),” in 1st International Workshop on Replication in Empirical Software Engineering Research, vol. 1, 2010, pp. 1–4.
- J. C. Carver, N. Juristo, M. T. Baldassarre, and S. Vegas, “Replications of software engineering experiments,” Empirical Software Engineering, vol. 19, no. 2. Springer Science and Business Media LLC, pp. 267–276, Dec. 05, 2013. https://doi.org/10.1007/s10664-013-9290-8.
- S. Heckman, J. C. Carver, M. Sherriff, and A. Al-zubidy, “A Systematic Literature Review of Empiricism and Norms of Reporting in Computing Education Research Literature,” ACM Transactions on Computing Education, vol. 22, no. 1. Association for Computing Machinery (ACM), pp. 1–46, Mar. 31, 2022. https://doi.org/10.1145/3470652.
- F. Q. B. da Silva et al., “Replication of empirical studies in software engineering research: a systematic mapping study,” Empirical Software Engineering. Springer Science and Business Media LLC, Sep. 01, 2012. https://doi.org/10.1007/s10664-012-9227-7.
- B. Kitchenham, “The role of replications in empirical software engineering—a word of warning,” Empirical Software Engineering, vol. 13, no. 2. Springer Science and Business Media LLC, pp. 219–221, Jan. 29, 2008. https://doi.org/10.1007/s10664-008-9061-0.
- A. R. Dennis and J. S. Valacich, “A replication manifesto,” AIS Transactions on Replication Research, vol. 1, no. 1, p. 1, 2015

## Exemplars
- T. Kosar, S. Gaberc, J. Carver, and M. Mernik. “Program Comprehension of Domain-Specific and General-Purpose Languages: Replication of a Family of Experiments Using Integrated Development Environments”. Empirical Software Engineering 23, 2734–2763 (2018). https://doi.org/10.1007/s10664-017-9593-2.
- F. Khan, I. David, D. Varro, and S. McIntosh, “Code Cloning in Smart Contracts on the Ethereum Platform: An Extended Replication Study,” IEEE Transactions on Software Engineering. Institute of Electrical and Electronics Engineers (IEEE), pp. 1–13, 2022. https://doi.org/10.1109/tse.2022.3207428.
- D. Fucci and B. Turhan, “On the role of tests in test-driven development: a differentiated and partial replication,” Empirical Software Engineering, vol. 19, no. 2. Springer Science and Business Media LLC, pp. 277–302, Jun. 21, 2013. https://doi.org/10.1007/s10664-013-9259-7.
- C. Apa, O. Dieste, E. G. Espinosa G., and E. R. Fonseca C., “Effectiveness for detecting faults within and outside the scope of testing techniques: an independent replication,” Empirical Software Engineering, vol. 19, no. 2. Springer Science and Business Media LLC, pp. 378–417, Aug. 08, 2013. https://doi.org/10.1007/s10664-013-9267-7.
- J. Itkonen and M. V. Mäntylä, “Are test cases needed? Replicated comparison between exploratory and test-case-based software testing,” Empirical Software Engineering, vol. 19, no. 2. Springer Science and Business Media LLC, pp. 303–342, Jul. 11, 2013. https://doi.org/10.1007/s10664-013-9266-8.
- M. N. Gómez and S. T. Acuña, “A replicated quasi-experimental study on the influence of personality and team climate in software development,” Empirical Software Engineering, vol. 19, no. 2. Springer Science and Business Media LLC, pp. 343–377, Aug. 02, 2013. https://doi.org/10.1007/s10664-013-9265-9.

---
<footnote><sup>[1](#footnote1)</sup>See Carver et al. (2013).</footnote><br/>
<footnote><sup>[2](#footnote2)</sup>Exact replication: same research questions, same method, same context. Methodological replication: same research questions, same method, different context. Conceptual replication: same research questions, different method, different context. (Dennis and Valacich, 2015)</footnote><br/>
<footnote><sup>[3](#footnote3)</sup>Partial replication: addresses a subset of the original research questions. Complete replication: addresses each of the original reseach questions. Extended replication: addresses each of the original reseach questions and additional ones. (Carver, 2010)</footnote><br/>
<footnote><sup>[4](#footnote4)</sup>Internal replication: the replicating team is the same as the original study's team. External replication: the replicating team is different from the original study's team. Mixed replication: overlaps exist between the replicating team and the original study's team. (da Silva et al., 2012)</footnote><br/>
