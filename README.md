# Empirical Standards

This repository contains the ACM SIGSOFT Empirical Standards for researchers, peer reviewers, editors and publications venues.

## What's an Empirical Standard?

An _Empirical Standard_ is a brief public document that communicates expectations for emprical research. Here _empirical_ just means that the researches uses data. The data can be qualitative or quantitative; real or synthetic. _Empirical_ distinguishes research that involves collecting and analyzing data from other kinds of scholarship like a mathematical proof or a philosophical treatise. 

Moreover, our empirical standards are:

1. Method-specific. Software engineering researchers use lots and lots of different research methods. If we tried to write one standard for all empirical research, it would either be biased against some methods or be so vague as to be almost useless. Our expectations for a controlled experiment are quite different from our expectations from an ethnographic case study. Therefore, we have different standards for different methods (e.g. questionnaire survey, systematic literature review, action research).
2. Models of the software engineering community's expectations. That is, we don't just make up the empirical standards based on a single person's opinion. The standards should reflect the views of the community. Obviously not everyone agrees on every point. However, most of a standard should appear reasonable to most of the subset of our community that's familiar with that kind of research. Over time should help build consensus over time.
  
## What are Empirical Standards for?

The empirical standards have two main use cases:

1. Fixing peer review
2. Educating graduate students

Scholarly peer review is simultaneously “the lynchpin about which the wholebusiness of science is pivoted" [1] and "prejudiced, capricious, inefficient, ineffective, and generally unscientific” [2]. Peer review has many problems, but many of them boil down to this: reviewers make up their own evaluation criteria. Devising appropriate evaluation criteria for any given manuscript is really, really difficult, so most reviewers' criteria are not very good. Reviewers create criteria that are inconsistent with each others', the venue's, the editors, the methodological literature and---crucially---the authors. Reviewers create criteria that are factually wrong, unreasonable, and unforeseeable. In effect, the real criteria by which our research is judged are not merely opaque; they don't even exist until the manuscript is submitted. This is why peer review is so frustrating, unpredictable, and unscientific.   

## Repository Structure

The standards themselves can be found in the _docs_ directory. There is a **General Standard**, which applies to all empirical research, and a set of specific standards, which apply to specific research methods such as **Case Studies**, **Controlled Experiments** and **Systematic Literature Reviews**.

In the _Supplements_ directory, you will find a set of supplemental standards that address cross-cutting concerns including **Information Visualization**,  **Sampling** and **Inter-rater Reliability and Agreement**. 

In the _Resources_ directory you'll find slide decks, links to videos and other materials about the standards.

In the main directory: 
 - Contributing.md gives advice on contributing to the standards
 - Empirical_Standards_Report.pdf explains how the standards were created, their costs and benefits, how they should be used and governed, and the scientific basis of the empirical standards initiative. 
 - HowToCite.md explains how to reference the standards 
 - LICENSE.md explains the creative commons license used by the standards

## References

[1] John M Ziman. 1968.Public knowledge: An essay concerning the socialdimension of science. Vol. 519. CUP Archive.
[2] Paul Ralph. 2016. Practical suggestions for improving scholarly peer review quality and reducing cycle times. _Communications of the Association for Information Systems_ 38, 1 (2016), Article 13.
